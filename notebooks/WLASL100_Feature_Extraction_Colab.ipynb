{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WLASL100 Feature Extraction on Google Colab\n",
    "\n",
    "This notebook extracts MediaPipe features for 100-sign WLASL dataset.\n",
    "\n",
    "**Runtime**: Select **GPU** runtime (Runtime → Change runtime type → GPU)\n",
    "\n",
    "**Estimated time**: 2-3 hours on Colab GPU (vs 30+ hours on laptop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup - Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install MediaPipe and dependencies\n",
    "!pip install mediapipe opencv-python tqdm\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Mount Google Drive\n",
    "\n",
    "You'll need to upload your WLASL videos to Google Drive first.\n",
    "\n",
    "**Folder structure on Google Drive:**\n",
    "```\n",
    "My Drive/\n",
    "  └── asl_data/\n",
    "      ├── videos_100/          # Upload this folder from your laptop\n",
    "      │   ├── book/\n",
    "      │   ├── drink/\n",
    "      │   └── ...\n",
    "      └── metadata.json        # Upload metadata file\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Verify files are there\n",
    "import os\n",
    "data_dir = '/content/drive/MyDrive/asl_data'\n",
    "video_dir = f'{data_dir}/videos_100'\n",
    "metadata_path = f'{data_dir}/metadata.json'\n",
    "\n",
    "print(f\"Video directory exists: {os.path.exists(video_dir)}\")\n",
    "print(f\"Metadata exists: {os.path.exists(metadata_path)}\")\n",
    "\n",
    "if os.path.exists(video_dir):\n",
    "    # Count subdirectories (glosses)\n",
    "    glosses = [d for d in os.listdir(video_dir) if os.path.isdir(f'{video_dir}/{d}')]\n",
    "    print(f\"Found {len(glosses)} gloss directories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Download MediaPipe Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory\n",
    "!mkdir -p /content/models/mediapipe\n",
    "\n",
    "# Download MediaPipe models with verification\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "models = [\n",
    "    {\n",
    "        'name': 'hand_landmarker.task',\n",
    "        'url': 'https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task',\n",
    "        'min_size': 1_000_000  # At least 1MB\n",
    "    },\n",
    "    {\n",
    "        'name': 'face_landmarker.task',\n",
    "        'url': 'https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task',\n",
    "        'min_size': 1_000_000\n",
    "    },\n",
    "    {\n",
    "        'name': 'pose_landmarker.task',\n",
    "        'url': 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_full/float16/1/pose_landmarker_full.task',\n",
    "        'min_size': 1_000_000\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Downloading MediaPipe models...\\n\")\n",
    "\n",
    "for model in models:\n",
    "    filepath = f\"/content/models/mediapipe/{model['name']}\"\n",
    "    \n",
    "    # Check if already exists and valid\n",
    "    if os.path.exists(filepath):\n",
    "        size = os.path.getsize(filepath)\n",
    "        if size >= model['min_size']:\n",
    "            print(f\"✓ {model['name']} already exists ({size:,} bytes)\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"⚠ {model['name']} exists but too small ({size} bytes), re-downloading...\")\n",
    "            os.remove(filepath)\n",
    "    \n",
    "    # Download\n",
    "    print(f\"  Downloading {model['name']}...\", end=\" \")\n",
    "    try:\n",
    "        urllib.request.urlretrieve(model['url'], filepath)\n",
    "        size = os.path.getsize(filepath)\n",
    "        print(f\"✓ ({size:,} bytes)\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ FAILED: {e}\")\n",
    "        raise\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Verify all models are accessible\n",
    "for model in models:\n",
    "    filepath = f\"/content/models/mediapipe/{model['name']}\"\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"Missing: {filepath}\")\n",
    "    \n",
    "    size = os.path.getsize(filepath)\n",
    "    if size < model['min_size']:\n",
    "        raise ValueError(f\"File too small: {filepath} ({size} bytes)\")\n",
    "    \n",
    "    # Check read permissions\n",
    "    with open(filepath, 'rb') as f:\n",
    "        f.read(1024)  # Try reading first 1KB\n",
    "    \n",
    "    print(f\"✓ {model['name']:30s} {size:>10,} bytes  [OK]\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"✓ All MediaPipe models ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Upload Code Files\n",
    "\n",
    "Upload these files from your laptop:\n",
    "- `mediapipe_extractor_v2.py`\n",
    "- `features.py`\n",
    "\n",
    "Or paste them directly in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Upload files manually using Colab's file upload\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()  # Select mediapipe_extractor_v2.py and features.py\n",
    "\n",
    "# Option 2: Copy from Google Drive (if you uploaded them there)\n",
    "!cp /content/drive/MyDrive/asl_data/code/mediapipe_extractor_v2.py /content/\n",
    "!cp /content/drive/MyDrive/asl_data/code/features.py /content/\n",
    "\n",
    "# FIX: Replace relative imports with absolute imports for Colab\n",
    "import os\n",
    "\n",
    "# Fix features.py relative import\n",
    "with open('/content/features.py', 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Change: from .mediapipe_extractor_v2 import RawLandmarks\n",
    "# To:     from mediapipe_extractor_v2 import RawLandmarks\n",
    "content = content.replace('from .mediapipe_extractor_v2 import', 'from mediapipe_extractor_v2 import')\n",
    "\n",
    "with open('/content/features.py', 'w') as f:\n",
    "    f.write(content)\n",
    "\n",
    "print(\"✓ Code files ready (import fix applied)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4.5: Fix MediaPipe Model Paths for Colab\n",
    "\n",
    "The extractor expects models in a specific location. We'll patch it to use Colab paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix MediaPipe model paths in the extractor\n",
    "with open('/content/mediapipe_extractor_v2.py', 'r') as f:\n",
    "    extractor_code = f.read()\n",
    "\n",
    "# Replace the hardcoded relative paths with Colab paths\n",
    "replacements = [\n",
    "    # Hand landmarker\n",
    "    ('model_path = str(Path(__file__).parent.parent.parent / \"models\" / \"mediapipe\" / \"hand_landmarker.task\")',\n",
    "     'model_path = \"/content/models/mediapipe/hand_landmarker.task\"'),\n",
    "    \n",
    "    # Face landmarker\n",
    "    ('model_path = str(Path(__file__).parent.parent.parent / \"models\" / \"mediapipe\" / \"face_landmarker.task\")',\n",
    "     'model_path = \"/content/models/mediapipe/face_landmarker.task\"'),\n",
    "    \n",
    "    # Pose landmarker (also fix the filename from pose_landmarker_full.task to pose_landmarker.task)\n",
    "    ('model_path = str(Path(__file__).parent.parent.parent / \"models\" / \"mediapipe\" / \"pose_landmarker_full.task\")',\n",
    "     'model_path = \"/content/models/mediapipe/pose_landmarker.task\"'),\n",
    "]\n",
    "\n",
    "for old, new in replacements:\n",
    "    extractor_code = extractor_code.replace(old, new)\n",
    "\n",
    "with open('/content/mediapipe_extractor_v2.py', 'w') as f:\n",
    "    f.write(extractor_code)\n",
    "\n",
    "print(\"✓ MediaPipe model paths fixed for Colab\")\n",
    "print(\"  hand_landmarker.task → /content/models/mediapipe/\")\n",
    "print(\"  face_landmarker.task → /content/models/mediapipe/\")\n",
    "print(\"  pose_landmarker.task → /content/models/mediapipe/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4.6: Test MediaPipe Initialization\n",
    "\n",
    "Quick test to ensure MediaPipe can load all models before starting extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test MediaPipe initialization\n",
    "print(\"Testing MediaPipe extractor initialization...\\n\")\n",
    "\n",
    "try:\n",
    "    from mediapipe_extractor_v2 import MediaPipeExtractor\n",
    "    \n",
    "    # This will load all 3 models\n",
    "    test_extractor = MediaPipeExtractor(\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"✓ SUCCESS: MediaPipe initialized correctly!\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"All model files are accessible and working.\")\n",
    "    print(\"Ready to start feature extraction.\")\n",
    "    \n",
    "except RuntimeError as e:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"✗ ERROR: MediaPipe initialization failed!\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"\\nPossible issues:\")\n",
    "    print(\"1. Model files not downloaded correctly (check Step 3)\")\n",
    "    print(\"2. Model paths not patched correctly (check Step 4.5)\")\n",
    "    print(\"3. Model files corrupted\")\n",
    "    print(\"\\nRun Step 3 again to re-download models.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "# Import our code\n",
    "from mediapipe_extractor_v2 import MediaPipeExtractor\n",
    "from features import FeatureExtractor\n",
    "\n",
    "# Configuration\n",
    "METADATA_PATH = metadata_path\n",
    "VIDEO_DIR = Path(video_dir)\n",
    "OUTPUT_DIR = Path('/content/output')  # Save to Colab storage first\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Create temp directory for local video copies\n",
    "TEMP_DIR = Path('/content/temp_videos')\n",
    "TEMP_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# OPTIMIZATION SETTINGS\n",
    "FRAME_SKIP = 2          # Process every 2nd frame (2x speedup)\n",
    "MAX_FRAMES = 500        # Cap at 500 frames per video\n",
    "MIN_SUCCESS_RATE = 0.7  # Skip videos with <70% frame detection\n",
    "\n",
    "def load_metadata():\n",
    "    \"\"\"Load WLASL metadata.\"\"\"\n",
    "    with open(METADATA_PATH, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    gloss_data = {}\n",
    "    for entry in metadata:\n",
    "        gloss = entry['gloss']\n",
    "        gloss_data[gloss] = entry['instances']\n",
    "    \n",
    "    # Top 100 glosses by video count\n",
    "    sorted_glosses = sorted(gloss_data.items(),\n",
    "                           key=lambda x: len(x[1]),\n",
    "                           reverse=True)[:100]\n",
    "    \n",
    "    print(f\"✓ Loaded metadata for 100 glosses\")\n",
    "    print(f\"  Total videos: {sum(len(v) for _, v in sorted_glosses)}\")\n",
    "    \n",
    "    return dict(sorted_glosses)\n",
    "\n",
    "def find_video_file(video_id: str, gloss: str, video_dir: Path) -> Path:\n",
    "    \"\"\"Find video file in gloss subdirectory.\n",
    "    \n",
    "    Tries multiple strategies:\n",
    "    1. Exact match: {video_id}.mp4\n",
    "    2. Try other extensions: .avi, .mov, .mkv\n",
    "    3. Match by stem (filename without extension)\n",
    "    \"\"\"\n",
    "    gloss_dir = video_dir / gloss\n",
    "    if not gloss_dir.exists():\n",
    "        return None\n",
    "    \n",
    "    # Strategy 1: Try exact match with .mp4\n",
    "    video_file = gloss_dir / f\"{video_id}.mp4\"\n",
    "    if video_file.exists():\n",
    "        return video_file\n",
    "    \n",
    "    # Strategy 2: Try other common video extensions\n",
    "    for ext in ['.avi', '.mov', '.mkv', '.webm', '.flv']:\n",
    "        video_file = gloss_dir / f\"{video_id}{ext}\"\n",
    "        if video_file.exists():\n",
    "            return video_file\n",
    "    \n",
    "    # Strategy 3: Search for any file with matching stem (filename without extension)\n",
    "    # This handles cases where video_id might have slight variations\n",
    "    for video_file in gloss_dir.glob(\"*\"):\n",
    "        if video_file.is_file() and video_file.stem == video_id:\n",
    "            return video_file\n",
    "    \n",
    "    # Strategy 4: Case-insensitive match\n",
    "    video_id_lower = video_id.lower()\n",
    "    for video_file in gloss_dir.glob(\"*\"):\n",
    "        if video_file.is_file() and video_file.stem.lower() == video_id_lower:\n",
    "            return video_file\n",
    "    \n",
    "    return None\n",
    "\n",
    "def copy_video_to_local(video_path: Path, max_retries: int = 3) -> Path:\n",
    "    \"\"\"\n",
    "    Copy video from Google Drive to local Colab storage.\n",
    "    \n",
    "    FIX for errno=11: MediaPipe can't handle Google Drive FUSE mount I/O.\n",
    "    Copying to local storage avoids network latency and rate limiting.\n",
    "    \"\"\"\n",
    "    local_path = TEMP_DIR / video_path.name\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            shutil.copy2(str(video_path), str(local_path))\n",
    "            return local_path\n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(0.5 * (attempt + 1))  # Exponential backoff\n",
    "                continue\n",
    "            else:\n",
    "                raise RuntimeError(f\"Failed to copy {video_path} after {max_retries} attempts: {e}\")\n",
    "    \n",
    "    return local_path\n",
    "\n",
    "def extract_features_optimized(mp_extractor, feature_extractor, video_path):\n",
    "    \"\"\"Optimized feature extraction with frame sampling.\"\"\"\n",
    "    import cv2\n",
    "    \n",
    "    # FIX: Copy video to local storage first to avoid Google Drive I/O issues\n",
    "    try:\n",
    "        local_video_path = copy_video_to_local(video_path)\n",
    "    except Exception as e:\n",
    "        return None, f\"copy_failed: {e}\"\n",
    "    \n",
    "    try:\n",
    "        cap = cv2.VideoCapture(str(local_video_path))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        # Skip very long videos (>5 minutes)\n",
    "        if total_frames > 9000:\n",
    "            cap.release()\n",
    "            local_video_path.unlink()  # Clean up temp file\n",
    "            return None, \"video_too_long\"\n",
    "        \n",
    "        landmarks_sequence = []\n",
    "        frame_idx = 0\n",
    "        frames_processed = 0\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "            \n",
    "            # Frame sampling: process every FRAME_SKIP frames\n",
    "            if frame_idx % FRAME_SKIP != 0:\n",
    "                frame_idx += 1\n",
    "                continue\n",
    "            \n",
    "            # Stop at max frames\n",
    "            if frames_processed >= MAX_FRAMES:\n",
    "                break\n",
    "            \n",
    "            # Convert to RGB\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            timestamp = frame_idx / fps if fps > 0 else frame_idx * (1/30.0)\n",
    "            \n",
    "            # Extract landmarks\n",
    "            landmarks = mp_extractor.extract_frame(frame_rgb, timestamp)\n",
    "            \n",
    "            if landmarks is not None:\n",
    "                landmarks_sequence.append(landmarks)\n",
    "            \n",
    "            frame_idx += 1\n",
    "            frames_processed += 1\n",
    "            \n",
    "            # Early exit if success rate is too low\n",
    "            if frames_processed >= 50:\n",
    "                success_rate = len(landmarks_sequence) / frames_processed\n",
    "                if success_rate < MIN_SUCCESS_RATE:\n",
    "                    cap.release()\n",
    "                    local_video_path.unlink()  # Clean up temp file\n",
    "                    return None, \"low_quality\"\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        # Clean up temp file\n",
    "        local_video_path.unlink()\n",
    "        \n",
    "        if len(landmarks_sequence) == 0:\n",
    "            return None, \"no_detections\"\n",
    "        \n",
    "        # Extract features\n",
    "        feature_sequence = []\n",
    "        for landmarks in landmarks_sequence:\n",
    "            feats = feature_extractor.extract_features(landmarks, include_temporal=True)\n",
    "            feature_sequence.append(feats.concatenate())\n",
    "        \n",
    "        features = np.array(feature_sequence, dtype=np.float32)\n",
    "        \n",
    "        return features, \"success\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Clean up temp file on error\n",
    "        if local_video_path.exists():\n",
    "            local_video_path.unlink()\n",
    "        return None, f\"extraction_error: {str(e)}\"\n",
    "\n",
    "def extract_split(gloss_data, split):\n",
    "    \"\"\"Extract features for train/val/test split.\"\"\"\n",
    "    mp_extractor = MediaPipeExtractor(\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5\n",
    "    )\n",
    "    feature_extractor = FeatureExtractor()\n",
    "    \n",
    "    cache_data = {}\n",
    "    gloss_to_id = {}\n",
    "    next_gloss_id = 1\n",
    "    \n",
    "    # Collect split instances\n",
    "    split_instances = []\n",
    "    for gloss, instances in gloss_data.items():\n",
    "        for instance in instances:\n",
    "            if instance['split'] == split:\n",
    "                split_instances.append((gloss, instance))\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Extracting {split.upper()} features (OPTIMIZED)\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Videos: {len(split_instances)}\")\n",
    "    print(f\"Frame skip: {FRAME_SKIP} (sampling every {FRAME_SKIP}th frame)\")\n",
    "    print(f\"Max frames: {MAX_FRAMES}\")\n",
    "    print(f\"Min success rate: {MIN_SUCCESS_RATE:.0%}\")\n",
    "    print(f\"FIX: Copying videos to local storage to avoid Drive I/O issues\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    stats = defaultdict(int)\n",
    "    \n",
    "    for gloss, instance in tqdm(split_instances, desc=f\"{split} extraction\"):\n",
    "        video_id = instance['video_id']\n",
    "        video_path = find_video_file(video_id, gloss, VIDEO_DIR)\n",
    "        \n",
    "        if not video_path or not video_path.exists():\n",
    "            stats['missing_file'] += 1\n",
    "            continue\n",
    "        \n",
    "        features, status = extract_features_optimized(mp_extractor, feature_extractor, video_path)\n",
    "        \n",
    "        if features is None:\n",
    "            stats[status] += 1\n",
    "            continue\n",
    "        \n",
    "        # Assign gloss ID\n",
    "        if gloss not in gloss_to_id:\n",
    "            gloss_to_id[gloss] = next_gloss_id\n",
    "            next_gloss_id += 1\n",
    "        \n",
    "        cache_data[video_id] = {\n",
    "            'features': features,\n",
    "            'gloss': gloss,\n",
    "            'gloss_id': gloss_to_id[gloss],\n",
    "            'video_id': video_id,\n",
    "            'split': split,\n",
    "        }\n",
    "        \n",
    "        stats['success'] += 1\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{split.upper()} Summary\")\n",
    "    print(f\"{'='*70}\")\n",
    "    for key, count in sorted(stats.items()):\n",
    "        print(f\"  {key}: {count}\")\n",
    "    print(f\"  Success rate: {stats['success'] / len(split_instances) * 100:.1f}%\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return cache_data, gloss_to_id\n",
    "\n",
    "print(\"✓ Feature extraction functions ready (with Drive I/O fix)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Import our code\n",
    "from mediapipe_extractor_v2 import MediaPipeExtractor\n",
    "from features import FeatureExtractor\n",
    "\n",
    "# Configuration\n",
    "METADATA_PATH = metadata_path\n",
    "VIDEO_DIR = Path(video_dir)\n",
    "OUTPUT_DIR = Path('/content/output')  # Save to Colab storage first\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# OPTIMIZATION SETTINGS\n",
    "FRAME_SKIP = 2          # Process every 2nd frame (2x speedup)\n",
    "MAX_FRAMES = 500        # Cap at 500 frames per video\n",
    "MIN_SUCCESS_RATE = 0.7  # Skip videos with <70% frame detection\n",
    "\n",
    "def load_metadata():\n",
    "    \"\"\"Load WLASL metadata.\"\"\"\n",
    "    with open(METADATA_PATH, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    gloss_data = {}\n",
    "    for entry in metadata:\n",
    "        gloss = entry['gloss']\n",
    "        gloss_data[gloss] = entry['instances']\n",
    "    \n",
    "    # Top 100 glosses by video count\n",
    "    sorted_glosses = sorted(gloss_data.items(),\n",
    "                           key=lambda x: len(x[1]),\n",
    "                           reverse=True)[:100]\n",
    "    \n",
    "    print(f\"✓ Loaded metadata for 100 glosses\")\n",
    "    print(f\"  Total videos: {sum(len(v) for _, v in sorted_glosses)}\")\n",
    "    \n",
    "    return dict(sorted_glosses)\n",
    "\n",
    "def find_video_file(video_id: str, gloss: str, video_dir: Path) -> Path:\n",
    "    \"\"\"Find video file in gloss subdirectory.\"\"\"\n",
    "    gloss_dir = video_dir / gloss\n",
    "    if not gloss_dir.exists():\n",
    "        return None\n",
    "    \n",
    "    video_file = gloss_dir / f\"{video_id}.mp4\"\n",
    "    return video_file if video_file.exists() else None\n",
    "\n",
    "def extract_features_optimized(mp_extractor, feature_extractor, video_path):\n",
    "    \"\"\"Optimized feature extraction with frame sampling.\"\"\"\n",
    "    import cv2\n",
    "    \n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Skip very long videos (>5 minutes)\n",
    "    if total_frames > 9000:\n",
    "        cap.release()\n",
    "        return None, \"video_too_long\"\n",
    "    \n",
    "    landmarks_sequence = []\n",
    "    frame_idx = 0\n",
    "    frames_processed = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        \n",
    "        # Frame sampling: process every FRAME_SKIP frames\n",
    "        if frame_idx % FRAME_SKIP != 0:\n",
    "            frame_idx += 1\n",
    "            continue\n",
    "        \n",
    "        # Stop at max frames\n",
    "        if frames_processed >= MAX_FRAMES:\n",
    "            break\n",
    "        \n",
    "        # Convert to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        timestamp = frame_idx / fps if fps > 0 else frame_idx * (1/30.0)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        landmarks = mp_extractor.extract_frame(frame_rgb, timestamp)\n",
    "        \n",
    "        if landmarks is not None:\n",
    "            landmarks_sequence.append(landmarks)\n",
    "        \n",
    "        frame_idx += 1\n",
    "        frames_processed += 1\n",
    "        \n",
    "        # Early exit if success rate is too low\n",
    "        if frames_processed >= 50:\n",
    "            success_rate = len(landmarks_sequence) / frames_processed\n",
    "            if success_rate < MIN_SUCCESS_RATE:\n",
    "                cap.release()\n",
    "                return None, \"low_quality\"\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    if len(landmarks_sequence) == 0:\n",
    "        return None, \"no_detections\"\n",
    "    \n",
    "    # Extract features\n",
    "    feature_sequence = []\n",
    "    for landmarks in landmarks_sequence:\n",
    "        feats = feature_extractor.extract_features(landmarks, include_temporal=True)\n",
    "        feature_sequence.append(feats.concatenate())\n",
    "    \n",
    "    features = np.array(feature_sequence, dtype=np.float32)\n",
    "    \n",
    "    return features, \"success\"\n",
    "\n",
    "def extract_split(gloss_data, split):\n",
    "    \"\"\"Extract features for train/val/test split.\"\"\"\n",
    "    mp_extractor = MediaPipeExtractor(\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5\n",
    "    )\n",
    "    feature_extractor = FeatureExtractor()\n",
    "    \n",
    "    cache_data = {}\n",
    "    gloss_to_id = {}\n",
    "    next_gloss_id = 1\n",
    "    \n",
    "    # Collect split instances\n",
    "    split_instances = []\n",
    "    for gloss, instances in gloss_data.items():\n",
    "        for instance in instances:\n",
    "            if instance['split'] == split:\n",
    "                split_instances.append((gloss, instance))\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Extracting {split.upper()} features (OPTIMIZED)\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Videos: {len(split_instances)}\")\n",
    "    print(f\"Frame skip: {FRAME_SKIP} (sampling every {FRAME_SKIP}th frame)\")\n",
    "    print(f\"Max frames: {MAX_FRAMES}\")\n",
    "    print(f\"Min success rate: {MIN_SUCCESS_RATE:.0%}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    stats = defaultdict(int)\n",
    "    \n",
    "    for gloss, instance in tqdm(split_instances, desc=f\"{split} extraction\"):\n",
    "        video_id = instance['video_id']\n",
    "        video_path = find_video_file(video_id, gloss, VIDEO_DIR)\n",
    "        \n",
    "        if not video_path or not video_path.exists():\n",
    "            stats['missing_file'] += 1\n",
    "            continue\n",
    "        \n",
    "        features, status = extract_features_optimized(mp_extractor, feature_extractor, video_path)\n",
    "        \n",
    "        if features is None:\n",
    "            stats[status] += 1\n",
    "            continue\n",
    "        \n",
    "        # Assign gloss ID\n",
    "        if gloss not in gloss_to_id:\n",
    "            gloss_to_id[gloss] = next_gloss_id\n",
    "            next_gloss_id += 1\n",
    "        \n",
    "        cache_data[video_id] = {\n",
    "            'features': features,\n",
    "            'gloss': gloss,\n",
    "            'gloss_id': gloss_to_id[gloss],\n",
    "            'video_id': video_id,\n",
    "            'split': split,\n",
    "        }\n",
    "        \n",
    "        stats['success'] += 1\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{split.upper()} Summary\")\n",
    "    print(f\"{'='*70}\")\n",
    "    for key, count in sorted(stats.items()):\n",
    "        print(f\"  {key}: {count}\")\n",
    "    print(f\"  Success rate: {stats['success'] / len(split_instances) * 100:.1f}%\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return cache_data, gloss_to_id\n",
    "\n",
    "print(\"✓ Feature extraction functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5.5: Diagnostic - Check Video File Paths\n",
    "\n",
    "Before running extraction, let's verify that video files can be found. This diagnostic will help identify any path or naming issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic: Check video file paths and naming\n",
    "print(\"=\"*70)\n",
    "print(\"DIAGNOSTIC: Checking video file paths\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get video directory (use the same path as defined in Step 4)\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Check if Google Drive is mounted\n",
    "drive_base = Path('/content/drive/MyDrive')\n",
    "print(f\"\\nGoogle Drive base: {drive_base}\")\n",
    "print(f\"Google Drive mounted: {drive_base.exists()}\\n\")\n",
    "\n",
    "if not drive_base.exists():\n",
    "    print(\"ERROR: Google Drive is not mounted!\")\n",
    "    print(\"Please run Step 2 (Mount Google Drive) first.\\n\")\n",
    "else:\n",
    "    # Check what's in MyDrive\n",
    "    print(\"Contents of /content/drive/MyDrive:\")\n",
    "    try:\n",
    "        items = list(drive_base.iterdir())\n",
    "        for item in sorted(items)[:20]:  # Show first 20 items\n",
    "            item_type = \"DIR\" if item.is_dir() else \"FILE\"\n",
    "            print(f\"  [{item_type}] {item.name}\")\n",
    "        if len(items) > 20:\n",
    "            print(f\"  ... and {len(items) - 20} more items\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error listing directory: {e}\")\n",
    "    print()\n",
    "\n",
    "# Check expected paths\n",
    "video_dir_diag = Path(video_dir) if 'video_dir' in globals() else Path('/content/drive/MyDrive/asl_data/videos_100')\n",
    "metadata_path_diag = metadata_path if 'metadata_path' in globals() else '/content/drive/MyDrive/asl_data/metadata.json'\n",
    "\n",
    "print(f\"Expected video directory: {video_dir_diag}\")\n",
    "print(f\"Expected metadata path: {metadata_path_diag}\\n\")\n",
    "\n",
    "# Check if asl_data directory exists\n",
    "asl_data_dir = video_dir_diag.parent\n",
    "print(f\"Checking parent directory: {asl_data_dir}\")\n",
    "if asl_data_dir.exists():\n",
    "    print(f\"✓ asl_data directory exists\")\n",
    "    print(f\"\\nContents of {asl_data_dir}:\")\n",
    "    try:\n",
    "        items = list(asl_data_dir.iterdir())\n",
    "        for item in sorted(items):\n",
    "            item_type = \"DIR\" if item.is_dir() else \"FILE\"\n",
    "            size = \"\"\n",
    "            if item.is_file():\n",
    "                try:\n",
    "                    size = f\" ({os.path.getsize(item):,} bytes)\"\n",
    "                except:\n",
    "                    pass\n",
    "            print(f\"  [{item_type}] {item.name}{size}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")\n",
    "else:\n",
    "    print(f\"✗ asl_data directory does not exist\")\n",
    "    print(f\"\\nPlease check:\")\n",
    "    print(f\"  1. Did you upload the videos_100 folder to Google Drive?\")\n",
    "    print(f\"  2. Is it in the correct location: MyDrive/asl_data/videos_100/\")\n",
    "    print(f\"  3. Check the exact folder name (case-sensitive)\")\n",
    "    print()\n",
    "\n",
    "# Load metadata to check video_id format\n",
    "import json\n",
    "with open(metadata_path_diag, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "gloss_data_diag = {}\n",
    "for entry in metadata:\n",
    "    gloss = entry['gloss']\n",
    "    gloss_data_diag[gloss] = entry['instances']\n",
    "\n",
    "# Top 100 glosses by video count\n",
    "sorted_glosses = sorted(gloss_data_diag.items(),\n",
    "                       key=lambda x: len(x[1]),\n",
    "                       reverse=True)[:100]\n",
    "gloss_data_diag = dict(sorted_glosses)\n",
    "\n",
    "# Check first few glosses and their video files\n",
    "print(f\"\\nVideo directory: {video_dir_diag}\")\n",
    "print(f\"Video directory exists: {video_dir_diag.exists()}\\n\")\n",
    "\n",
    "if video_dir_diag.exists():\n",
    "    # List first few gloss directories\n",
    "    gloss_dirs = [d for d in sorted(video_dir_diag.iterdir()) if d.is_dir()][:5]\n",
    "    print(f\"Sample gloss directories found: {[d.name for d in gloss_dirs]}\\n\")\n",
    "    \n",
    "    # Check a few examples from metadata\n",
    "    sample_count = 0\n",
    "    for gloss, instances in list(gloss_data_diag.items())[:3]:\n",
    "        if sample_count >= 3:\n",
    "            break\n",
    "        print(f\"Gloss: {gloss}\")\n",
    "        print(f\"  Instances: {len(instances)}\")\n",
    "        \n",
    "        # Check if gloss directory exists\n",
    "        gloss_dir = video_dir_diag / gloss\n",
    "        print(f\"  Directory exists: {gloss_dir.exists()}\")\n",
    "        \n",
    "        if gloss_dir.exists():\n",
    "            # List files in directory\n",
    "            files = list(gloss_dir.glob(\"*\"))\n",
    "            print(f\"  Files in directory: {len(files)}\")\n",
    "            if files:\n",
    "                print(f\"  Sample files: {[f.name for f in files[:3]]}\")\n",
    "            \n",
    "            # Check first instance\n",
    "            if instances:\n",
    "                first_instance = instances[0]\n",
    "                video_id = first_instance['video_id']\n",
    "                print(f\"  First video_id from metadata: {video_id}\")\n",
    "                expected_path = gloss_dir / f\"{video_id}.mp4\"\n",
    "                print(f\"  Expected path: {expected_path}\")\n",
    "                print(f\"  File exists: {expected_path.exists()}\")\n",
    "                \n",
    "                # Try to find any .mp4 file\n",
    "                mp4_files = list(gloss_dir.glob(\"*.mp4\"))\n",
    "                if mp4_files:\n",
    "                    print(f\"  Found .mp4 files: {[f.name for f in mp4_files[:3]]}\")\n",
    "                    # Check if video_id matches any file (without extension)\n",
    "                    matching = [f for f in mp4_files if f.stem == video_id]\n",
    "                    if matching:\n",
    "                        print(f\"  ✓ Found matching file: {matching[0].name}\")\n",
    "                    else:\n",
    "                        print(f\"  ✗ No file matches video_id '{video_id}'\")\n",
    "                        if mp4_files:\n",
    "                            print(f\"    File stems: {[f.stem for f in mp4_files[:3]]}\")\n",
    "        print()\n",
    "        sample_count += 1\n",
    "else:\n",
    "    print(f\"ERROR: Video directory does not exist: {video_dir_diag}\")\n",
    "    print(f\"Please check Step 2 (Mount Google Drive) and verify the path is correct.\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "gloss_data = load_metadata()\n",
    "\n",
    "# Extract all splits\n",
    "all_gloss_to_id = {}\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    cache_data, gloss_to_id = extract_split(gloss_data, split)\n",
    "    all_gloss_to_id.update(gloss_to_id)\n",
    "    \n",
    "    # Save to pickle\n",
    "    output_file = OUTPUT_DIR / f\"features_{split}_wlasl100.pkl\"\n",
    "    with open(output_file, 'wb') as f:\n",
    "        pickle.dump(cache_data, f)\n",
    "    \n",
    "    print(f\"✓ Saved {len(cache_data)} features to {output_file}\")\n",
    "\n",
    "# Save vocabulary\n",
    "vocab_file = OUTPUT_DIR / \"vocabulary.json\"\n",
    "vocab_data = {\n",
    "    'gloss_to_id': all_gloss_to_id,\n",
    "    'id_to_gloss': {v: k for k, v in all_gloss_to_id.items()},\n",
    "    'vocab_size': len(all_gloss_to_id) + 1,\n",
    "    'num_glosses': len(all_gloss_to_id),\n",
    "}\n",
    "\n",
    "with open(vocab_file, 'w') as f:\n",
    "    json.dump(vocab_data, f, indent=2)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"EXTRACTION COMPLETE!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Files created in {OUTPUT_DIR}:\")\n",
    "print(f\"  - features_train_wlasl100.pkl\")\n",
    "print(f\"  - features_val_wlasl100.pkl\")\n",
    "print(f\"  - features_test_wlasl100.pkl\")\n",
    "print(f\"  - vocabulary.json\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Download Results\n",
    "\n",
    "Copy results back to Google Drive so you can download them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy to Google Drive\n",
    "import shutil\n",
    "\n",
    "drive_output = '/content/drive/MyDrive/asl_data/extracted_features'\n",
    "!mkdir -p {drive_output}\n",
    "\n",
    "!cp /content/output/*.pkl {drive_output}/\n",
    "!cp /content/output/*.json {drive_output}/\n",
    "\n",
    "print(f\"✓ Results saved to Google Drive: {drive_output}\")\n",
    "print(\"\\nYou can now download these files to your laptop!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
